{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaymabaya/reconnaissace-faciale/blob/main/comparaison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "R3tYcquxkCGX",
        "outputId": "607eb907-5b1c-42a4-bfa6-093ee752aa4c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-409bf530-152c-4aab-b7bc-596635db0fff\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-409bf530-152c-4aab-b7bc-596635db0fff\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving emotion_detection_mobilenet.zip to emotion_detection_mobilenet.zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ho6RlhuHkWmn"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"emotion_detection_mobilenet.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJAHbaKuljxa",
        "outputId": "616fcd5b-e529-4124-cab4-c49eade72fe5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nombre total d’images chargées : 28709\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "dataset_path = \"/content/dataset/train\"\n",
        "classes = sorted(os.listdir(dataset_path))\n",
        "\n",
        "X, y = [], []\n",
        "for label_index, class_name in enumerate(classes):\n",
        "    class_path = os.path.join(dataset_path, class_name)\n",
        "\n",
        "    # Vérifie que c’est bien un dossier\n",
        "    if not os.path.isdir(class_path):\n",
        "        continue\n",
        "\n",
        "    for image_name in os.listdir(class_path):\n",
        "        img_path = os.path.join(class_path, image_name)\n",
        "\n",
        "        # Vérifie que c’est un fichier (et non un dossier)\n",
        "        if not os.path.isfile(img_path):\n",
        "            continue\n",
        "\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "        if img is not None:\n",
        "            try:\n",
        "                img = cv2.resize(img, (48, 48))\n",
        "                X.append(img)\n",
        "                y.append(label_index)\n",
        "            except:\n",
        "                print(f\"Erreur de redimensionnement : {img_path}\")\n",
        "        else:\n",
        "            print(f\"Image non chargée : {img_path}\")\n",
        "\n",
        "# Conversion finale\n",
        "X = np.array(X).reshape(-1, 48, 48, 1) / 255.0\n",
        "y = to_categorical(y, num_classes=len(classes))\n",
        "\n",
        "print(f\"Nombre total d’images chargées : {len(X)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5RgiMD4pdhS",
        "outputId": "82347274-e095-49c4-89e0-ab39c091ff2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 28709 images, Test: 7178 images\n"
          ]
        }
      ],
      "source": [
        "def load_dataset(path):\n",
        "    classes = sorted(os.listdir(path))\n",
        "    X, y = [], []\n",
        "    for label_index, class_name in enumerate(classes):\n",
        "        class_path = os.path.join(path, class_name)\n",
        "        if not os.path.isdir(class_path):\n",
        "            continue\n",
        "        for image_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, image_name)\n",
        "            if not os.path.isfile(img_path):\n",
        "                continue\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is not None:\n",
        "                img = cv2.resize(img, (48, 48))\n",
        "                X.append(img)\n",
        "                y.append(label_index)\n",
        "    X = np.array(X).reshape(-1, 48, 48, 1) / 255.0\n",
        "    y = to_categorical(y, num_classes=len(classes))\n",
        "    return X, y, classes\n",
        "\n",
        "X_train, y_train, classes = load_dataset('/content/dataset/train')\n",
        "X_test, y_test, _ = load_dataset('/content/dataset/test')\n",
        "\n",
        "print(f\"Train: {len(X_train)} images, Test: {len(X_test)} images\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aF9e2Rgpiuh",
        "outputId": "9334b449-d649-4359-bd27-1748087a9ef9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 20ms/step - accuracy: 0.2338 - loss: 1.8282 - val_accuracy: 0.1878 - val_loss: 1.8252\n",
            "Epoch 2/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 7ms/step - accuracy: 0.2777 - loss: 1.7565 - val_accuracy: 0.3136 - val_loss: 1.7159\n",
            "Epoch 3/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3067 - loss: 1.7211 - val_accuracy: 0.2838 - val_loss: 1.8345\n",
            "Epoch 4/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3291 - loss: 1.6906 - val_accuracy: 0.2873 - val_loss: 1.7558\n",
            "Epoch 5/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3409 - loss: 1.6688 - val_accuracy: 0.1991 - val_loss: 1.9339\n",
            "Epoch 6/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3503 - loss: 1.6515 - val_accuracy: 0.3617 - val_loss: 1.6120\n",
            "Epoch 7/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3538 - loss: 1.6353 - val_accuracy: 0.3803 - val_loss: 1.5856\n",
            "Epoch 8/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.3696 - loss: 1.6099 - val_accuracy: 0.3363 - val_loss: 1.6397\n",
            "Epoch 9/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3666 - loss: 1.6087 - val_accuracy: 0.3498 - val_loss: 1.5970\n",
            "Epoch 10/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3864 - loss: 1.5825 - val_accuracy: 0.3828 - val_loss: 1.5564\n",
            "Epoch 11/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.3933 - loss: 1.5628 - val_accuracy: 0.3625 - val_loss: 1.6063\n",
            "Epoch 12/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3985 - loss: 1.5508 - val_accuracy: 0.3661 - val_loss: 1.5933\n",
            "Epoch 13/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.3996 - loss: 1.5538 - val_accuracy: 0.4147 - val_loss: 1.5315\n",
            "Epoch 14/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4098 - loss: 1.5326 - val_accuracy: 0.3338 - val_loss: 1.7455\n",
            "Epoch 15/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4099 - loss: 1.5257 - val_accuracy: 0.4092 - val_loss: 1.5256\n",
            "Epoch 16/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4116 - loss: 1.5206 - val_accuracy: 0.4394 - val_loss: 1.4766\n",
            "Epoch 17/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4214 - loss: 1.5109 - val_accuracy: 0.4193 - val_loss: 1.4882\n",
            "Epoch 18/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4220 - loss: 1.5051 - val_accuracy: 0.3986 - val_loss: 1.5146\n",
            "Epoch 19/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4285 - loss: 1.4876 - val_accuracy: 0.4503 - val_loss: 1.4480\n",
            "Epoch 20/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4337 - loss: 1.4843 - val_accuracy: 0.4306 - val_loss: 1.4653\n",
            "Epoch 21/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4295 - loss: 1.4922 - val_accuracy: 0.3353 - val_loss: 1.8652\n",
            "Epoch 22/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4251 - loss: 1.4842 - val_accuracy: 0.3260 - val_loss: 1.8821\n",
            "Epoch 23/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4331 - loss: 1.4775 - val_accuracy: 0.4429 - val_loss: 1.4542\n",
            "Epoch 24/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4346 - loss: 1.4719 - val_accuracy: 0.4313 - val_loss: 1.4846\n",
            "Epoch 25/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4429 - loss: 1.4696 - val_accuracy: 0.3625 - val_loss: 1.6330\n",
            "Epoch 26/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4375 - loss: 1.4631 - val_accuracy: 0.3782 - val_loss: 1.5364\n",
            "Epoch 27/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4425 - loss: 1.4638 - val_accuracy: 0.4097 - val_loss: 1.4995\n",
            "Epoch 28/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4413 - loss: 1.4605 - val_accuracy: 0.4315 - val_loss: 1.4630\n",
            "Epoch 29/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.4463 - loss: 1.4540 - val_accuracy: 0.4498 - val_loss: 1.4382\n",
            "Epoch 30/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4425 - loss: 1.4556 - val_accuracy: 0.3950 - val_loss: 1.5801\n",
            "Epoch 31/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4491 - loss: 1.4497 - val_accuracy: 0.4728 - val_loss: 1.4013\n",
            "Epoch 32/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4491 - loss: 1.4347 - val_accuracy: 0.4501 - val_loss: 1.4533\n",
            "Epoch 33/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4443 - loss: 1.4483 - val_accuracy: 0.4361 - val_loss: 1.4773\n",
            "Epoch 34/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4478 - loss: 1.4371 - val_accuracy: 0.4575 - val_loss: 1.4477\n",
            "Epoch 35/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4552 - loss: 1.4218 - val_accuracy: 0.4646 - val_loss: 1.4057\n",
            "Epoch 36/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4497 - loss: 1.4411 - val_accuracy: 0.4631 - val_loss: 1.3956\n",
            "Epoch 37/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.4574 - loss: 1.4177 - val_accuracy: 0.4252 - val_loss: 1.4676\n",
            "Epoch 38/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4508 - loss: 1.4269 - val_accuracy: 0.4792 - val_loss: 1.3913\n",
            "Epoch 39/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4649 - loss: 1.4196 - val_accuracy: 0.4712 - val_loss: 1.3928\n",
            "Epoch 40/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4585 - loss: 1.4206 - val_accuracy: 0.4759 - val_loss: 1.3733\n",
            "Epoch 41/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4578 - loss: 1.4148 - val_accuracy: 0.4699 - val_loss: 1.3909\n",
            "Epoch 42/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4562 - loss: 1.4191 - val_accuracy: 0.4609 - val_loss: 1.4288\n",
            "Epoch 43/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4595 - loss: 1.4175 - val_accuracy: 0.4870 - val_loss: 1.3844\n",
            "Epoch 44/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4645 - loss: 1.4097 - val_accuracy: 0.4393 - val_loss: 1.4569\n",
            "Epoch 45/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4606 - loss: 1.4065 - val_accuracy: 0.4571 - val_loss: 1.4082\n",
            "Epoch 46/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4639 - loss: 1.4096 - val_accuracy: 0.4018 - val_loss: 1.5631\n",
            "Epoch 47/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4632 - loss: 1.4115 - val_accuracy: 0.4565 - val_loss: 1.4216\n",
            "Epoch 48/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4614 - loss: 1.4044 - val_accuracy: 0.4891 - val_loss: 1.3612\n",
            "Epoch 49/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4646 - loss: 1.3982 - val_accuracy: 0.4404 - val_loss: 1.4358\n",
            "Epoch 50/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4645 - loss: 1.3945 - val_accuracy: 0.4007 - val_loss: 1.5391\n",
            "Epoch 51/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4580 - loss: 1.4060 - val_accuracy: 0.4745 - val_loss: 1.3681\n",
            "Epoch 52/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4617 - loss: 1.4020 - val_accuracy: 0.4795 - val_loss: 1.3846\n",
            "Epoch 53/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4706 - loss: 1.3920 - val_accuracy: 0.4721 - val_loss: 1.4011\n",
            "Epoch 54/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4713 - loss: 1.3867 - val_accuracy: 0.4490 - val_loss: 1.4251\n",
            "Epoch 55/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4712 - loss: 1.3888 - val_accuracy: 0.4447 - val_loss: 1.4381\n",
            "Epoch 56/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4720 - loss: 1.3793 - val_accuracy: 0.4833 - val_loss: 1.3744\n",
            "Epoch 57/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4700 - loss: 1.3850 - val_accuracy: 0.2841 - val_loss: 2.1879\n",
            "Epoch 58/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4723 - loss: 1.3818 - val_accuracy: 0.4707 - val_loss: 1.3718\n",
            "Epoch 59/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4733 - loss: 1.3793 - val_accuracy: 0.1942 - val_loss: 3.0341\n",
            "Epoch 60/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4745 - loss: 1.3763 - val_accuracy: 0.4709 - val_loss: 1.3729\n",
            "Epoch 61/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4749 - loss: 1.3839 - val_accuracy: 0.4544 - val_loss: 1.4120\n",
            "Epoch 62/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4759 - loss: 1.3759 - val_accuracy: 0.4649 - val_loss: 1.3940\n",
            "Epoch 63/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4675 - loss: 1.3792 - val_accuracy: 0.4961 - val_loss: 1.3341\n",
            "Epoch 64/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4794 - loss: 1.3691 - val_accuracy: 0.4868 - val_loss: 1.3489\n",
            "Epoch 65/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4785 - loss: 1.3748 - val_accuracy: 0.4969 - val_loss: 1.3516\n",
            "Epoch 66/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4780 - loss: 1.3684 - val_accuracy: 0.4496 - val_loss: 1.4116\n",
            "Epoch 67/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4729 - loss: 1.3768 - val_accuracy: 0.4575 - val_loss: 1.4035\n",
            "Epoch 68/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4838 - loss: 1.3607 - val_accuracy: 0.4576 - val_loss: 1.4080\n",
            "Epoch 69/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.4726 - loss: 1.3778 - val_accuracy: 0.2835 - val_loss: 2.3886\n",
            "Epoch 70/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4815 - loss: 1.3678 - val_accuracy: 0.3437 - val_loss: 1.8629\n",
            "Epoch 71/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4773 - loss: 1.3705 - val_accuracy: 0.4263 - val_loss: 1.4942\n",
            "Epoch 72/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4767 - loss: 1.3717 - val_accuracy: 0.4847 - val_loss: 1.3598\n",
            "Epoch 73/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4730 - loss: 1.3720 - val_accuracy: 0.4324 - val_loss: 1.4763\n",
            "Epoch 74/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4809 - loss: 1.3626 - val_accuracy: 0.3600 - val_loss: 1.9074\n",
            "Epoch 75/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4767 - loss: 1.3697 - val_accuracy: 0.4742 - val_loss: 1.3636\n",
            "Epoch 76/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4805 - loss: 1.3693 - val_accuracy: 0.4720 - val_loss: 1.3640\n",
            "Epoch 77/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4821 - loss: 1.3539 - val_accuracy: 0.4128 - val_loss: 1.5241\n",
            "Epoch 78/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4839 - loss: 1.3621 - val_accuracy: 0.4425 - val_loss: 1.4208\n",
            "Epoch 79/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4796 - loss: 1.3643 - val_accuracy: 0.4122 - val_loss: 1.5401\n",
            "Epoch 80/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4778 - loss: 1.3647 - val_accuracy: 0.4787 - val_loss: 1.3528\n",
            "Epoch 81/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4825 - loss: 1.3574 - val_accuracy: 0.4941 - val_loss: 1.3486\n",
            "Epoch 82/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4844 - loss: 1.3550 - val_accuracy: 0.4939 - val_loss: 1.3260\n",
            "Epoch 83/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4795 - loss: 1.3561 - val_accuracy: 0.4791 - val_loss: 1.3572\n",
            "Epoch 84/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4888 - loss: 1.3454 - val_accuracy: 0.5102 - val_loss: 1.3254\n",
            "Epoch 85/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4918 - loss: 1.3414 - val_accuracy: 0.4528 - val_loss: 1.4134\n",
            "Epoch 86/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4836 - loss: 1.3500 - val_accuracy: 0.4404 - val_loss: 1.4825\n",
            "Epoch 87/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4907 - loss: 1.3493 - val_accuracy: 0.4865 - val_loss: 1.3355\n",
            "Epoch 88/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4818 - loss: 1.3580 - val_accuracy: 0.4974 - val_loss: 1.3216\n",
            "Epoch 89/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4847 - loss: 1.3524 - val_accuracy: 0.4507 - val_loss: 1.4099\n",
            "Epoch 90/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4949 - loss: 1.3360 - val_accuracy: 0.4714 - val_loss: 1.3964\n",
            "Epoch 91/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4822 - loss: 1.3554 - val_accuracy: 0.4911 - val_loss: 1.3338\n",
            "Epoch 92/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4942 - loss: 1.3352 - val_accuracy: 0.4078 - val_loss: 1.6632\n",
            "Epoch 93/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4897 - loss: 1.3443 - val_accuracy: 0.4423 - val_loss: 1.4537\n",
            "Epoch 94/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4823 - loss: 1.3450 - val_accuracy: 0.3456 - val_loss: 1.7467\n",
            "Epoch 95/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4951 - loss: 1.3402 - val_accuracy: 0.4861 - val_loss: 1.3427\n",
            "Epoch 96/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4859 - loss: 1.3546 - val_accuracy: 0.3433 - val_loss: 1.7740\n",
            "Epoch 97/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.4837 - loss: 1.3457 - val_accuracy: 0.4795 - val_loss: 1.3548\n",
            "Epoch 98/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4901 - loss: 1.3400 - val_accuracy: 0.4653 - val_loss: 1.3782\n",
            "Epoch 99/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4938 - loss: 1.3297 - val_accuracy: 0.4971 - val_loss: 1.3314\n",
            "Epoch 100/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4894 - loss: 1.3402 - val_accuracy: 0.5113 - val_loss: 1.3023\n",
            "Epoch 101/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4931 - loss: 1.3329 - val_accuracy: 0.4806 - val_loss: 1.3571\n",
            "Epoch 102/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4935 - loss: 1.3291 - val_accuracy: 0.4976 - val_loss: 1.3355\n",
            "Epoch 103/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4965 - loss: 1.3342 - val_accuracy: 0.4859 - val_loss: 1.3550\n",
            "Epoch 104/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4906 - loss: 1.3326 - val_accuracy: 0.4700 - val_loss: 1.3771\n",
            "Epoch 105/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4904 - loss: 1.3379 - val_accuracy: 0.4388 - val_loss: 1.4531\n",
            "Epoch 106/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4893 - loss: 1.3417 - val_accuracy: 0.4894 - val_loss: 1.3483\n",
            "Epoch 107/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4938 - loss: 1.3332 - val_accuracy: 0.5198 - val_loss: 1.2874\n",
            "Epoch 108/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4905 - loss: 1.3385 - val_accuracy: 0.5111 - val_loss: 1.2975\n",
            "Epoch 109/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4897 - loss: 1.3357 - val_accuracy: 0.5121 - val_loss: 1.3063\n",
            "Epoch 110/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4943 - loss: 1.3320 - val_accuracy: 0.4908 - val_loss: 1.3338\n",
            "Epoch 111/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4893 - loss: 1.3381 - val_accuracy: 0.3713 - val_loss: 1.5858\n",
            "Epoch 112/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4911 - loss: 1.3326 - val_accuracy: 0.4912 - val_loss: 1.3164\n",
            "Epoch 113/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4905 - loss: 1.3328 - val_accuracy: 0.4680 - val_loss: 1.3743\n",
            "Epoch 114/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5000 - loss: 1.3216 - val_accuracy: 0.5004 - val_loss: 1.3103\n",
            "Epoch 115/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.4886 - loss: 1.3341 - val_accuracy: 0.5024 - val_loss: 1.3385\n",
            "Epoch 116/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4897 - loss: 1.3351 - val_accuracy: 0.5220 - val_loss: 1.2798\n",
            "Epoch 117/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4910 - loss: 1.3343 - val_accuracy: 0.5014 - val_loss: 1.3380\n",
            "Epoch 118/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4871 - loss: 1.3381 - val_accuracy: 0.4731 - val_loss: 1.3539\n",
            "Epoch 119/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4963 - loss: 1.3168 - val_accuracy: 0.5075 - val_loss: 1.3052\n",
            "Epoch 120/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5019 - loss: 1.3261 - val_accuracy: 0.4837 - val_loss: 1.3433\n",
            "Epoch 121/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4953 - loss: 1.3258 - val_accuracy: 0.4961 - val_loss: 1.3118\n",
            "Epoch 122/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4940 - loss: 1.3248 - val_accuracy: 0.4975 - val_loss: 1.3112\n",
            "Epoch 123/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4957 - loss: 1.3216 - val_accuracy: 0.4767 - val_loss: 1.3741\n",
            "Epoch 124/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4946 - loss: 1.3289 - val_accuracy: 0.4390 - val_loss: 1.4564\n",
            "Epoch 125/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4920 - loss: 1.3312 - val_accuracy: 0.4653 - val_loss: 1.4075\n",
            "Epoch 126/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4956 - loss: 1.3268 - val_accuracy: 0.4749 - val_loss: 1.3722\n",
            "Epoch 127/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4929 - loss: 1.3203 - val_accuracy: 0.4799 - val_loss: 1.3480\n",
            "Epoch 128/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4955 - loss: 1.3180 - val_accuracy: 0.4802 - val_loss: 1.3500\n",
            "Epoch 129/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4922 - loss: 1.3277 - val_accuracy: 0.4986 - val_loss: 1.3233\n",
            "Epoch 130/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4907 - loss: 1.3259 - val_accuracy: 0.5130 - val_loss: 1.2798\n",
            "Epoch 131/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4949 - loss: 1.3286 - val_accuracy: 0.4854 - val_loss: 1.3589\n",
            "Epoch 132/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4980 - loss: 1.3295 - val_accuracy: 0.5092 - val_loss: 1.2973\n",
            "Epoch 133/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.4944 - loss: 1.3283 - val_accuracy: 0.4958 - val_loss: 1.3158\n",
            "Epoch 134/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4986 - loss: 1.3183 - val_accuracy: 0.4503 - val_loss: 1.4244\n",
            "Epoch 135/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4948 - loss: 1.3158 - val_accuracy: 0.4937 - val_loss: 1.3429\n",
            "Epoch 136/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4966 - loss: 1.3261 - val_accuracy: 0.4590 - val_loss: 1.4412\n",
            "Epoch 137/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4944 - loss: 1.3270 - val_accuracy: 0.5114 - val_loss: 1.2981\n",
            "Epoch 138/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4955 - loss: 1.3186 - val_accuracy: 0.4781 - val_loss: 1.3986\n",
            "Epoch 139/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5008 - loss: 1.3165 - val_accuracy: 0.4863 - val_loss: 1.3563\n",
            "Epoch 140/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4917 - loss: 1.3255 - val_accuracy: 0.5109 - val_loss: 1.2871\n",
            "Epoch 141/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.4944 - loss: 1.3263 - val_accuracy: 0.5117 - val_loss: 1.2921\n",
            "Epoch 142/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4945 - loss: 1.3280 - val_accuracy: 0.4844 - val_loss: 1.3452\n",
            "Epoch 143/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4989 - loss: 1.3152 - val_accuracy: 0.5125 - val_loss: 1.2902\n",
            "Epoch 144/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4948 - loss: 1.3274 - val_accuracy: 0.5124 - val_loss: 1.2984\n",
            "Epoch 145/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4999 - loss: 1.3183 - val_accuracy: 0.5210 - val_loss: 1.2697\n",
            "Epoch 146/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5004 - loss: 1.3181 - val_accuracy: 0.4989 - val_loss: 1.3137\n",
            "Epoch 147/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5054 - loss: 1.3136 - val_accuracy: 0.5117 - val_loss: 1.3031\n",
            "Epoch 148/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4999 - loss: 1.3123 - val_accuracy: 0.4728 - val_loss: 1.3760\n",
            "Epoch 149/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5019 - loss: 1.3140 - val_accuracy: 0.5273 - val_loss: 1.2716\n",
            "Epoch 150/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4956 - loss: 1.3182 - val_accuracy: 0.3950 - val_loss: 1.5971\n",
            "Epoch 151/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.4950 - loss: 1.3125 - val_accuracy: 0.5223 - val_loss: 1.2696\n",
            "Epoch 152/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5006 - loss: 1.3040 - val_accuracy: 0.5018 - val_loss: 1.3178\n",
            "Epoch 153/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4952 - loss: 1.3220 - val_accuracy: 0.5043 - val_loss: 1.2887\n",
            "Epoch 154/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5002 - loss: 1.3129 - val_accuracy: 0.4819 - val_loss: 1.3905\n",
            "Epoch 155/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4984 - loss: 1.3173 - val_accuracy: 0.3952 - val_loss: 1.5673\n",
            "Epoch 156/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.4955 - loss: 1.3113 - val_accuracy: 0.4925 - val_loss: 1.3306\n",
            "Epoch 157/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4999 - loss: 1.3158 - val_accuracy: 0.4805 - val_loss: 1.3516\n",
            "Epoch 158/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4982 - loss: 1.3093 - val_accuracy: 0.5042 - val_loss: 1.3167\n",
            "Epoch 159/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5044 - loss: 1.3078 - val_accuracy: 0.4802 - val_loss: 1.3615\n",
            "Epoch 160/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4926 - loss: 1.3201 - val_accuracy: 0.4893 - val_loss: 1.3314\n",
            "Epoch 161/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5034 - loss: 1.3142 - val_accuracy: 0.4989 - val_loss: 1.3414\n",
            "Epoch 162/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5014 - loss: 1.3102 - val_accuracy: 0.4565 - val_loss: 1.4289\n",
            "Epoch 163/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5004 - loss: 1.3094 - val_accuracy: 0.5038 - val_loss: 1.2925\n",
            "Epoch 164/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5009 - loss: 1.3061 - val_accuracy: 0.4900 - val_loss: 1.3550\n",
            "Epoch 165/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4976 - loss: 1.3128 - val_accuracy: 0.5170 - val_loss: 1.2873\n",
            "Epoch 166/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5068 - loss: 1.3111 - val_accuracy: 0.4767 - val_loss: 1.3728\n",
            "Epoch 167/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.5001 - loss: 1.3121 - val_accuracy: 0.4919 - val_loss: 1.3278\n",
            "Epoch 168/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4981 - loss: 1.3199 - val_accuracy: 0.5157 - val_loss: 1.2751\n",
            "Epoch 169/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5069 - loss: 1.3029 - val_accuracy: 0.5061 - val_loss: 1.2973\n",
            "Epoch 170/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5061 - loss: 1.3070 - val_accuracy: 0.5093 - val_loss: 1.3046\n",
            "Epoch 171/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5024 - loss: 1.3019 - val_accuracy: 0.5166 - val_loss: 1.2872\n",
            "Epoch 172/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5041 - loss: 1.3100 - val_accuracy: 0.5125 - val_loss: 1.3039\n",
            "Epoch 173/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5013 - loss: 1.3047 - val_accuracy: 0.5042 - val_loss: 1.3030\n",
            "Epoch 174/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4996 - loss: 1.3132 - val_accuracy: 0.4997 - val_loss: 1.3275\n",
            "Epoch 175/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5091 - loss: 1.3010 - val_accuracy: 0.5248 - val_loss: 1.2761\n",
            "Epoch 176/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.5026 - loss: 1.3113 - val_accuracy: 0.4335 - val_loss: 1.5052\n",
            "Epoch 177/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5128 - loss: 1.3003 - val_accuracy: 0.5128 - val_loss: 1.2881\n",
            "Epoch 178/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5055 - loss: 1.3074 - val_accuracy: 0.5199 - val_loss: 1.2776\n",
            "Epoch 179/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5040 - loss: 1.3017 - val_accuracy: 0.4772 - val_loss: 1.3906\n",
            "Epoch 180/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.4998 - loss: 1.3052 - val_accuracy: 0.4423 - val_loss: 1.4352\n",
            "Epoch 181/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.4995 - loss: 1.3121 - val_accuracy: 0.5039 - val_loss: 1.3079\n",
            "Epoch 182/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5008 - loss: 1.3127 - val_accuracy: 0.4287 - val_loss: 1.4819\n",
            "Epoch 183/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5045 - loss: 1.3007 - val_accuracy: 0.5301 - val_loss: 1.2608\n",
            "Epoch 184/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.4991 - loss: 1.3039 - val_accuracy: 0.4859 - val_loss: 1.3355\n",
            "Epoch 185/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5020 - loss: 1.3004 - val_accuracy: 0.5185 - val_loss: 1.2971\n",
            "Epoch 186/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5030 - loss: 1.2994 - val_accuracy: 0.5313 - val_loss: 1.2681\n",
            "Epoch 187/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5043 - loss: 1.3106 - val_accuracy: 0.4760 - val_loss: 1.3826\n",
            "Epoch 188/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5059 - loss: 1.3004 - val_accuracy: 0.5242 - val_loss: 1.2643\n",
            "Epoch 189/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5072 - loss: 1.3023 - val_accuracy: 0.5134 - val_loss: 1.2913\n",
            "Epoch 190/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.4994 - loss: 1.3133 - val_accuracy: 0.5070 - val_loss: 1.3107\n",
            "Epoch 191/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5089 - loss: 1.3027 - val_accuracy: 0.5162 - val_loss: 1.2801\n",
            "Epoch 192/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5001 - loss: 1.3090 - val_accuracy: 0.5017 - val_loss: 1.3140\n",
            "Epoch 193/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5061 - loss: 1.3083 - val_accuracy: 0.5010 - val_loss: 1.3156\n",
            "Epoch 194/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.5013 - loss: 1.3159 - val_accuracy: 0.5021 - val_loss: 1.3340\n",
            "Epoch 195/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5073 - loss: 1.3044 - val_accuracy: 0.4983 - val_loss: 1.3059\n",
            "Epoch 196/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.5041 - loss: 1.2994 - val_accuracy: 0.5315 - val_loss: 1.2685\n",
            "Epoch 197/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.4996 - loss: 1.3055 - val_accuracy: 0.3922 - val_loss: 1.5468\n",
            "Epoch 198/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5062 - loss: 1.3008 - val_accuracy: 0.4723 - val_loss: 1.3781\n",
            "Epoch 199/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.5016 - loss: 1.3039 - val_accuracy: 0.5208 - val_loss: 1.2832\n",
            "Epoch 200/200\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5011 - loss: 1.2938 - val_accuracy: 0.5043 - val_loss: 1.3249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, GlobalAveragePooling2D, Dense, SeparableConv2D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "def mini_xception(input_shape=(48,48,1), num_classes=7):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(8, (3,3), padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = SeparableConv2D(16, (3,3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = SeparableConv2D(32, (3,3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = SeparableConv2D(64, (3,3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D()(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = mini_xception()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=200, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "model.save('mini_xception_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ARm7Igd65lBm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "dataset_dir = \"/content/dataset\"\n",
        "categories = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "num_classes = len(categories)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for label_index, category in enumerate(categories):\n",
        "    for folder in ['train', 'test']:\n",
        "        folder_path = os.path.join(dataset_dir, folder, category)\n",
        "        if not os.path.exists(folder_path):\n",
        "            continue\n",
        "\n",
        "        for image_name in os.listdir(folder_path):\n",
        "            image_path = os.path.join(folder_path, image_name)\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.resize(img, (48, 48))  # Pour Mini-Xception\n",
        "            img = img / 255.0\n",
        "            img = np.expand_dims(img, axis=-1)  # Ajouter canal si image grayscale\n",
        "            X.append(img)\n",
        "            y.append(label_index)\n",
        "\n",
        "X = np.array(X, dtype=\"float32\")\n",
        "y = to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "# Séparer les données en entraînement et test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "txkR1zqG70Tb"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "img = cv2.resize(img, (48, 48))\n",
        "img = img / 255.0\n",
        "img = np.expand_dims(img, axis=-1)  # (48, 48, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDlrYJ8b8c3Y",
        "outputId": "6d5c06ae-4a10-43ec-9bb3-6c62094e266c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5115 - loss: 1.2936\n",
            "Mini-Xception Accuracy: 50.78%\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model_x = load_model('/content/mini_xception.h5')\n",
        "\n",
        "loss_x, acc_x = model_x.evaluate(X_test, y_test, verbose=1)\n",
        "print(f\"Mini-Xception Accuracy: {acc_x * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26ng30nsF8U7"
      },
      "source": [
        "MobelNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "h8WLpmQqFfuv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "dataset_dir = \"/content/dataset\"\n",
        "categories = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "num_classes = len(categories)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for label_index, category in enumerate(categories):\n",
        "    for folder in ['train', 'test']:\n",
        "        folder_path = os.path.join(dataset_dir, folder, category)\n",
        "        if not os.path.exists(folder_path):\n",
        "            continue\n",
        "\n",
        "        for image_name in os.listdir(folder_path):\n",
        "            image_path = os.path.join(folder_path, image_name)\n",
        "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # <-- Lecture en niveaux de gris\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.resize(img, (48, 48))\n",
        "            img = img / 255.0\n",
        "            img = np.expand_dims(img, axis=-1)  # <-- Pour obtenir (48, 48, 1)\n",
        "            X.append(img)\n",
        "            y.append(label_index)\n",
        "\n",
        "X = np.array(X, dtype=\"float32\")\n",
        "y = to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCYlgmDdG2Ml",
        "outputId": "093df674-b736-4a1a-f4e1-0dbec163b16b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-6a6d2d6c24ab>:11: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "Epoch 1/102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py:237: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
            "Expected: ['keras_tensor_383']\n",
            "Received: inputs=Tensor(shape=(None, 96, 96, 3))\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 115ms/step - accuracy: 0.4603 - loss: 1.4527 - val_accuracy: 0.5018 - val_loss: 2.4912\n",
            "Epoch 2/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.6124 - loss: 1.0310 - val_accuracy: 0.5398 - val_loss: 2.4151\n",
            "Epoch 3/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.6601 - loss: 0.9053 - val_accuracy: 0.5124 - val_loss: 2.3063\n",
            "Epoch 4/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - accuracy: 0.6890 - loss: 0.8386 - val_accuracy: 0.4217 - val_loss: 2.9153\n",
            "Epoch 5/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - accuracy: 0.7174 - loss: 0.7637 - val_accuracy: 0.3072 - val_loss: 4.2553\n",
            "Epoch 6/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - accuracy: 0.7467 - loss: 0.6975 - val_accuracy: 0.4631 - val_loss: 2.3292\n",
            "Epoch 7/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.7650 - loss: 0.6433 - val_accuracy: 0.5585 - val_loss: 2.1455\n",
            "Epoch 8/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.7905 - loss: 0.5785 - val_accuracy: 0.4377 - val_loss: 2.5143\n",
            "Epoch 9/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - accuracy: 0.8044 - loss: 0.5335 - val_accuracy: 0.4707 - val_loss: 2.2310\n",
            "Epoch 10/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.8341 - loss: 0.4606 - val_accuracy: 0.4784 - val_loss: 2.9182\n",
            "Epoch 11/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - accuracy: 0.8539 - loss: 0.4099 - val_accuracy: 0.5110 - val_loss: 2.1523\n",
            "Epoch 12/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.8716 - loss: 0.3614 - val_accuracy: 0.4471 - val_loss: 2.7671\n",
            "Epoch 13/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.8861 - loss: 0.3233 - val_accuracy: 0.3796 - val_loss: 2.5064\n",
            "Epoch 14/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - accuracy: 0.8994 - loss: 0.2836 - val_accuracy: 0.4713 - val_loss: 2.5108\n",
            "Epoch 15/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - accuracy: 0.9045 - loss: 0.2742 - val_accuracy: 0.4781 - val_loss: 2.6631\n",
            "Epoch 16/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - accuracy: 0.9187 - loss: 0.2376 - val_accuracy: 0.5496 - val_loss: 2.0878\n",
            "Epoch 17/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.9263 - loss: 0.2075 - val_accuracy: 0.4705 - val_loss: 3.1944\n",
            "Epoch 18/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.9277 - loss: 0.1998 - val_accuracy: 0.5300 - val_loss: 2.4088\n",
            "Epoch 19/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.9412 - loss: 0.1705 - val_accuracy: 0.5247 - val_loss: 2.3366\n",
            "Epoch 20/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.9416 - loss: 0.1695 - val_accuracy: 0.5437 - val_loss: 2.6549\n",
            "Epoch 21/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.9482 - loss: 0.1480 - val_accuracy: 0.5589 - val_loss: 2.2316\n",
            "Epoch 22/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.9543 - loss: 0.1369 - val_accuracy: 0.5502 - val_loss: 2.4829\n",
            "Epoch 23/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - accuracy: 0.9522 - loss: 0.1442 - val_accuracy: 0.5632 - val_loss: 2.3686\n",
            "Epoch 24/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.9538 - loss: 0.1313 - val_accuracy: 0.5522 - val_loss: 2.5326\n",
            "Epoch 25/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.9579 - loss: 0.1252 - val_accuracy: 0.5124 - val_loss: 2.2972\n",
            "Epoch 26/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.9394 - loss: 0.1755 - val_accuracy: 0.5373 - val_loss: 2.4567\n",
            "Epoch 27/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.9609 - loss: 0.1143 - val_accuracy: 0.5465 - val_loss: 2.5302\n",
            "Epoch 28/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - accuracy: 0.9630 - loss: 0.1075 - val_accuracy: 0.5775 - val_loss: 2.7887\n",
            "Epoch 29/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.9628 - loss: 0.1075 - val_accuracy: 0.6000 - val_loss: 2.4663\n",
            "Epoch 30/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - accuracy: 0.9667 - loss: 0.0970 - val_accuracy: 0.5143 - val_loss: 3.7356\n",
            "Epoch 31/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - accuracy: 0.9675 - loss: 0.0956 - val_accuracy: 0.5479 - val_loss: 2.7220\n",
            "Epoch 32/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - accuracy: 0.9638 - loss: 0.1030 - val_accuracy: 0.5800 - val_loss: 2.6138\n",
            "Epoch 33/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.9682 - loss: 0.0933 - val_accuracy: 0.5454 - val_loss: 2.7141\n",
            "Epoch 34/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.9653 - loss: 0.0992 - val_accuracy: 0.5511 - val_loss: 2.4037\n",
            "Epoch 35/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - accuracy: 0.9647 - loss: 0.1000 - val_accuracy: 0.5663 - val_loss: 2.5345\n",
            "Epoch 36/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.9645 - loss: 0.1030 - val_accuracy: 0.5506 - val_loss: 2.5153\n",
            "Epoch 37/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.9723 - loss: 0.0808 - val_accuracy: 0.5915 - val_loss: 2.2366\n",
            "Epoch 38/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - accuracy: 0.9651 - loss: 0.1008 - val_accuracy: 0.6120 - val_loss: 2.2470\n",
            "Epoch 39/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.9749 - loss: 0.0714 - val_accuracy: 0.5971 - val_loss: 2.4773\n",
            "Epoch 40/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 50ms/step - accuracy: 0.9734 - loss: 0.0774 - val_accuracy: 0.5665 - val_loss: 2.7993\n",
            "Epoch 41/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.9674 - loss: 0.0891 - val_accuracy: 0.5958 - val_loss: 2.8066\n",
            "Epoch 42/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.9729 - loss: 0.0749 - val_accuracy: 0.5805 - val_loss: 3.0614\n",
            "Epoch 43/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - accuracy: 0.9704 - loss: 0.0874 - val_accuracy: 0.5947 - val_loss: 2.7468\n",
            "Epoch 44/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - accuracy: 0.9763 - loss: 0.0680 - val_accuracy: 0.5992 - val_loss: 2.5715\n",
            "Epoch 45/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.9730 - loss: 0.0751 - val_accuracy: 0.6035 - val_loss: 2.5374\n",
            "Epoch 46/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.9728 - loss: 0.0755 - val_accuracy: 0.5800 - val_loss: 2.5647\n",
            "Epoch 47/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.9735 - loss: 0.0750 - val_accuracy: 0.5977 - val_loss: 2.2252\n",
            "Epoch 48/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - accuracy: 0.9747 - loss: 0.0699 - val_accuracy: 0.6062 - val_loss: 2.3774\n",
            "Epoch 49/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 52ms/step - accuracy: 0.9786 - loss: 0.0636 - val_accuracy: 0.5853 - val_loss: 2.7204\n",
            "Epoch 50/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.9699 - loss: 0.0827 - val_accuracy: 0.5925 - val_loss: 2.7064\n",
            "Epoch 51/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.9774 - loss: 0.0635 - val_accuracy: 0.5918 - val_loss: 2.3983\n",
            "Epoch 52/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 52ms/step - accuracy: 0.9826 - loss: 0.0495 - val_accuracy: 0.6174 - val_loss: 2.2401\n",
            "Epoch 53/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 50ms/step - accuracy: 0.9763 - loss: 0.0645 - val_accuracy: 0.5875 - val_loss: 2.5861\n",
            "Epoch 54/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 50ms/step - accuracy: 0.9781 - loss: 0.0622 - val_accuracy: 0.5887 - val_loss: 2.6175\n",
            "Epoch 55/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.9768 - loss: 0.0660 - val_accuracy: 0.5567 - val_loss: 2.7793\n",
            "Epoch 56/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - accuracy: 0.9740 - loss: 0.0756 - val_accuracy: 0.6035 - val_loss: 2.6233\n",
            "Epoch 57/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - accuracy: 0.9811 - loss: 0.0538 - val_accuracy: 0.5942 - val_loss: 2.5743\n",
            "Epoch 58/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 50ms/step - accuracy: 0.9829 - loss: 0.0503 - val_accuracy: 0.6050 - val_loss: 2.6135\n",
            "Epoch 59/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.9810 - loss: 0.0542 - val_accuracy: 0.5765 - val_loss: 2.9332\n",
            "Epoch 60/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.9801 - loss: 0.0535 - val_accuracy: 0.6025 - val_loss: 2.6672\n",
            "Epoch 61/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - accuracy: 0.9805 - loss: 0.0542 - val_accuracy: 0.6130 - val_loss: 2.5529\n",
            "Epoch 62/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.9821 - loss: 0.0523 - val_accuracy: 0.5991 - val_loss: 2.4880\n",
            "Epoch 63/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.9832 - loss: 0.0496 - val_accuracy: 0.6069 - val_loss: 2.5694\n",
            "Epoch 64/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.9808 - loss: 0.0535 - val_accuracy: 0.6031 - val_loss: 2.4387\n",
            "Epoch 65/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.9833 - loss: 0.0517 - val_accuracy: 0.5743 - val_loss: 2.6074\n",
            "Epoch 66/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.9798 - loss: 0.0565 - val_accuracy: 0.6062 - val_loss: 2.9150\n",
            "Epoch 67/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - accuracy: 0.9827 - loss: 0.0509 - val_accuracy: 0.6166 - val_loss: 2.5423\n",
            "Epoch 68/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - accuracy: 0.9839 - loss: 0.0479 - val_accuracy: 0.6103 - val_loss: 2.6258\n",
            "Epoch 69/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - accuracy: 0.9852 - loss: 0.0412 - val_accuracy: 0.6195 - val_loss: 2.5711\n",
            "Epoch 70/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.9839 - loss: 0.0493 - val_accuracy: 0.6048 - val_loss: 2.6211\n",
            "Epoch 71/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.9809 - loss: 0.0525 - val_accuracy: 0.6154 - val_loss: 2.6310\n",
            "Epoch 72/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 48ms/step - accuracy: 0.9840 - loss: 0.0463 - val_accuracy: 0.6055 - val_loss: 2.7958\n",
            "Epoch 73/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - accuracy: 0.9839 - loss: 0.0446 - val_accuracy: 0.6003 - val_loss: 2.9124\n",
            "Epoch 74/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.9817 - loss: 0.0498 - val_accuracy: 0.6225 - val_loss: 2.7815\n",
            "Epoch 75/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 48ms/step - accuracy: 0.9720 - loss: 0.0805 - val_accuracy: 0.6133 - val_loss: 2.6150\n",
            "Epoch 76/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.9859 - loss: 0.0411 - val_accuracy: 0.6205 - val_loss: 2.6089\n",
            "Epoch 77/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 48ms/step - accuracy: 0.9826 - loss: 0.0556 - val_accuracy: 0.6275 - val_loss: 2.6957\n",
            "Epoch 78/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.9863 - loss: 0.0393 - val_accuracy: 0.6226 - val_loss: 2.5662\n",
            "Epoch 79/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - accuracy: 0.9843 - loss: 0.0426 - val_accuracy: 0.6158 - val_loss: 2.6491\n",
            "Epoch 80/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - accuracy: 0.9851 - loss: 0.0408 - val_accuracy: 0.6307 - val_loss: 2.6144\n",
            "Epoch 81/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.9819 - loss: 0.0485 - val_accuracy: 0.6126 - val_loss: 2.6464\n",
            "Epoch 82/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - accuracy: 0.9861 - loss: 0.0386 - val_accuracy: 0.6310 - val_loss: 2.4720\n",
            "Epoch 83/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.9839 - loss: 0.0445 - val_accuracy: 0.6271 - val_loss: 2.5086\n",
            "Epoch 84/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - accuracy: 0.9879 - loss: 0.0355 - val_accuracy: 0.5970 - val_loss: 2.6730\n",
            "Epoch 85/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.9860 - loss: 0.0402 - val_accuracy: 0.6152 - val_loss: 2.6548\n",
            "Epoch 86/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.9861 - loss: 0.0408 - val_accuracy: 0.6181 - val_loss: 2.7015\n",
            "Epoch 87/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - accuracy: 0.9822 - loss: 0.0508 - val_accuracy: 0.6049 - val_loss: 2.8109\n",
            "Epoch 88/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.9857 - loss: 0.0416 - val_accuracy: 0.5933 - val_loss: 2.8829\n",
            "Epoch 89/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.9874 - loss: 0.0369 - val_accuracy: 0.6166 - val_loss: 2.5865\n",
            "Epoch 90/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - accuracy: 0.9852 - loss: 0.0412 - val_accuracy: 0.6233 - val_loss: 2.5474\n",
            "Epoch 91/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.9881 - loss: 0.0333 - val_accuracy: 0.6052 - val_loss: 2.7702\n",
            "Epoch 92/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 50ms/step - accuracy: 0.9889 - loss: 0.0320 - val_accuracy: 0.6076 - val_loss: 2.7470\n",
            "Epoch 93/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - accuracy: 0.9894 - loss: 0.0307 - val_accuracy: 0.6106 - val_loss: 2.8946\n",
            "Epoch 94/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - accuracy: 0.9827 - loss: 0.0476 - val_accuracy: 0.5595 - val_loss: 2.9281\n",
            "Epoch 95/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - accuracy: 0.9844 - loss: 0.0433 - val_accuracy: 0.6074 - val_loss: 2.5571\n",
            "Epoch 96/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 50ms/step - accuracy: 0.9902 - loss: 0.0278 - val_accuracy: 0.6174 - val_loss: 2.5745\n",
            "Epoch 97/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - accuracy: 0.9895 - loss: 0.0309 - val_accuracy: 0.6374 - val_loss: 2.4853\n",
            "Epoch 98/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 50ms/step - accuracy: 0.9862 - loss: 0.0394 - val_accuracy: 0.6212 - val_loss: 2.5544\n",
            "Epoch 99/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 51ms/step - accuracy: 0.9860 - loss: 0.0396 - val_accuracy: 0.6167 - val_loss: 2.8226\n",
            "Epoch 100/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - accuracy: 0.9862 - loss: 0.0374 - val_accuracy: 0.6152 - val_loss: 2.7360\n",
            "Epoch 101/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - accuracy: 0.9891 - loss: 0.0290 - val_accuracy: 0.6095 - val_loss: 2.8261\n",
            "Epoch 102/102\n",
            "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 48ms/step - accuracy: 0.9878 - loss: 0.0329 - val_accuracy: 0.5982 - val_loss: 2.8357\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "# Préparation des données pour MobileNet\n",
        "X_train_m = tf.image.resize(tf.image.grayscale_to_rgb(tf.convert_to_tensor(X_train)), (96,96))\n",
        "X_test_m = tf.image.resize(tf.image.grayscale_to_rgb(tf.convert_to_tensor(X_test)), (96,96))\n",
        "\n",
        "input_tensor = Input(shape=(96,96,3))\n",
        "base_model = MobileNetV2(input_tensor=input_tensor, include_top=False, weights='imagenet')\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model_mobilenet = Model(inputs=base_model.input, outputs=outputs)\n",
        "\n",
        "model_mobilenet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_mobilenet.fit(X_train_m, y_train, epochs=102, batch_size=64, validation_data=(X_test_m, y_test))\n",
        "\n",
        "model_mobilenet.save('mobilenet_emotion_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "dataset_dir = \"/content/dataset\"\n",
        "categories = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "num_classes = len(categories)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for label_index, category in enumerate(categories):\n",
        "    for folder in ['train', 'test']:\n",
        "        folder_path = os.path.join(dataset_dir, folder, category)\n",
        "        if not os.path.exists(folder_path):\n",
        "            continue\n",
        "\n",
        "        for image_name in os.listdir(folder_path):\n",
        "            image_path = os.path.join(folder_path, image_name)\n",
        "            img = cv2.imread(image_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.resize(img, (48, 48))  # Pour Mini-Xception\n",
        "            img = img / 255.0\n",
        "            img = np.expand_dims(img, axis=-1)  # Ajouter canal si image grayscale\n",
        "            X.append(img)\n",
        "            y.append(label_index)\n",
        "\n",
        "X = np.array(X, dtype=\"float32\")\n",
        "y = to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "# Séparer les données en entraînement et test\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "j6W8txl8cpKE"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "img = cv2.resize(img, (48, 48))\n",
        "img = img / 255.0\n",
        "img = np.expand_dims(img, axis=-1)  # (48, 48, 1)\n"
      ],
      "metadata": {
        "id": "eNbAtg2Jcs25"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Re-load the data specifically for MobileNet evaluation\n",
        "# This code block is copied from ipython-input-28-fd54d4dfe90b\n",
        "dataset_dir = \"/content/dataset\"\n",
        "categories = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
        "num_classes = len(categories)\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for label_index, category in enumerate(categories):\n",
        "    for folder in ['train', 'test']:\n",
        "        folder_path = os.path.join(dataset_dir, folder, category)\n",
        "        if not os.path.exists(folder_path):\n",
        "            continue\n",
        "\n",
        "        for image_name in os.listdir(folder_path):\n",
        "            image_path = os.path.join(folder_path, image_name)\n",
        "            # Read as grayscale\n",
        "            img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if img is None:\n",
        "                continue\n",
        "            img = cv2.resize(img, (48, 48))\n",
        "            img = img / 255.0\n",
        "            # Ensure shape is (48, 48, 1)\n",
        "            img = np.expand_dims(img, axis=-1)\n",
        "            X.append(img)\n",
        "            y.append(label_index)\n",
        "\n",
        "X = np.array(X, dtype=\"float32\")\n",
        "y = to_categorical(y, num_classes=num_classes)\n",
        "\n",
        "# Split the data again\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "model_x = load_model('/content/mobilenet_emotion_model.h5')\n",
        "\n",
        "# Préparation des données pour l'évaluation de MobileNet\n",
        "# Assurez-vous que les données ont le même format que celles utilisées pour l'entraînement\n",
        "# Redimensionner les images à (96, 96) et convertir en RGB\n",
        "X_test_m = tf.image.resize(tf.image.grayscale_to_rgb(tf.convert_to_tensor(X_test)), (96,96))\n",
        "\n",
        "loss_x, acc_x = model_x.evaluate(X_test_m, y_test, verbose=1)\n",
        "print(f\"mobilenet Accuracy: {acc_x * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSmyJSdPc6Sb",
        "outputId": "a9e78c4d-5b8b-49c0-a34e-56bf3d48bcd6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.6024 - loss: 2.8100\n",
            "mobilenet Accuracy: 59.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Noms des modèles\n",
        "models = ['Mini-Xception', 'MobileNet']\n",
        "\n",
        "# Leurs accuracies en pourcentage\n",
        "accuracies = [50.78, 59.82]\n",
        "\n",
        "# Création du diagramme en barres\n",
        "plt.figure(figsize=(8, 6))\n",
        "bars = plt.bar(models, accuracies, color=['skyblue', 'lightgreen'])\n",
        "\n",
        "# Ajouter les pourcentages au-dessus des barres\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, height + 1, f'{height:.2f}%', ha='center', fontsize=12)\n",
        "\n",
        "# Mise en forme\n",
        "plt.title(\"Comparaison de l'Accuracy finale des modèles\")\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.ylim(0, 100)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "DMG0gFY3eIO4",
        "outputId": "d95920ec-b32b-4f98-d345-b7822070922d"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOTuPsZwMLsIHFz6NDCiowj",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}